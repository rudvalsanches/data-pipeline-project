# Data Pipeline Project ğŸš€

Este projeto demonstra uma arquitetura completa de Engenharia de Dados, incluindo ingestÃ£o, processamento, armazenamento e visualizaÃ§Ã£o.

## ğŸ”¹ Tecnologias Utilizadas:
- ğŸ³ Docker + WSL2
- ğŸ—ï¸ Apache Airflow (OrquestraÃ§Ã£o)
- ğŸ”¥ Apache Spark (Processamento)
- ğŸ—„ï¸ PostgreSQL (Banco de Dados)
- â˜ï¸ MinIO (SimulaÃ§Ã£o do AWS S3 - Data Lake)
- ğŸ“Š Grafana + Prometheus (Monitoramento)
- ğŸ“ˆ Metabase (VisualizaÃ§Ã£o de Dados)

## ğŸ“‚ Estrutura do Projeto:# data-pipeline-project

ğŸ“ data-pipeline-project 
â”‚â”€â”€ ğŸ“ airflow/ # DAGs do Airflow 
â”‚â”€â”€ ğŸ“ ingestion/ # Scripts de ingestÃ£o (Python) 
â”‚â”€â”€ ğŸ“ processing/ # Scripts de processamento (Spark/Pandas) 
â”‚â”€â”€ ğŸ“ storage/ # ConfiguraÃ§Ã£o do PostgreSQL e MinIO 
â”‚â”€â”€ ğŸ“ monitoring/ # Prometheus e Grafana 
â”‚â”€â”€ ğŸ“ visualization/ # ConfiguraÃ§Ã£o do Metabase 
â”‚â”€â”€ ğŸ“ docker/ # Arquivos Docker 
â”‚â”€â”€ ğŸ“„ README.md # DocumentaÃ§Ã£o 
â”‚â”€â”€ ğŸ“„ docker-compose.yml # Arquitetura Docker 
â”‚â”€â”€ ğŸ“„ requirements.txt # DependÃªncias do Python